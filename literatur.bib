% LTeX: enabled=false

@misc{wang2019glue,
  archiveprefix = {arXiv},
  author        = {Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},
  eprint        = {1804.07461},
  primaryclass  = {cs.CL},
  title         = {GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
  year          = {2019}
}
@misc{zhou2023dont,
  archiveprefix = {arXiv},
  author        = {Kun Zhou and Yutao Zhu and Zhipeng Chen and Wentong Chen and Wayne Xin Zhao and Xu Chen and Yankai Lin and Ji-Rong Wen and Jiawei Han},
  eprint        = {2311.01964},
  primaryclass  = {cs.CL},
  title         = {Don't Make Your LLM an Evaluation Benchmark Cheater},
  year          = {2023}
}

@misc{birch2018findings,
  archiveprefix = {arXiv},
  author        = {Alexandra Birch and Andrew Finch and Minh-Thang Luong and Graham Neubig and Yusuke Oda},
  eprint        = {1806.02940},
  primaryclass  = {cs.CL},
  title         = {Findings of the Second Workshop on Neural Machine Translation and Generation},
  year          = {2018}
}
@misc{sakaguchi2019winogrande,
  archiveprefix = {arXiv},
  author        = {Keisuke Sakaguchi and Ronan Le Bras and Chandra Bhagavatula and Yejin Choi},
  eprint        = {1907.10641},
  primaryclass  = {cs.CL},
  title         = {WinoGrande: An Adversarial Winograd Schema Challenge at Scale},
  year          = {2019}
}
@misc{srivastava2023imitation,
  archiveprefix = {arXiv},
  author        = {Aarohi Srivastava and Abhinav Rastogi and Abhishek Rao and Abu Awal Md Shoeb and Abubakar Abid and Adam Fisch and Adam R. Brown and Adam Santoro and Aditya Gupta and Adrià Garriga-Alonso and Agnieszka Kluska and Aitor Lewkowycz and Akshat Agarwal and Alethea Power and Alex Ray and Alex Warstadt and Alexander W. Kocurek and Ali Safaya and Ali Tazarv and Alice Xiang and Alicia Parrish and Allen Nie and Aman Hussain and Amanda Askell and Amanda Dsouza and Ambrose Slone and Ameet Rahane and Anantharaman S. Iyer and Anders Andreassen and Andrea Madotto and Andrea Santilli and Andreas Stuhlmüller and Andrew Dai and Andrew La and Andrew Lampinen and Andy Zou and Angela Jiang and Angelica Chen and Anh Vuong and Animesh Gupta and Anna Gottardi and Antonio Norelli and Anu Venkatesh and Arash Gholamidavoodi and Arfa Tabassum and Arul Menezes and Arun Kirubarajan and Asher Mullokandov and Ashish Sabharwal and Austin Herrick and Avia Efrat and Aykut Erdem and Ayla Karakaş and B. Ryan Roberts and Bao Sheng Loe and Barret Zoph and Bartłomiej Bojanowski and Batuhan Özyurt and Behnam Hedayatnia and Behnam Neyshabur and Benjamin Inden and Benno Stein and Berk Ekmekci and Bill Yuchen Lin and Blake Howald and Bryan Orinion and Cameron Diao and Cameron Dour and Catherine Stinson and Cedrick Argueta and César Ferri Ramírez and Chandan Singh and Charles Rathkopf and Chenlin Meng and Chitta Baral and Chiyu Wu and Chris Callison-Burch and Chris Waites and Christian Voigt and Christopher D. Manning and Christopher Potts and Cindy Ramirez and Clara E. Rivera and Clemencia Siro and Colin Raffel and Courtney Ashcraft and Cristina Garbacea and Damien Sileo and Dan Garrette and Dan Hendrycks and Dan Kilman and Dan Roth and Daniel Freeman and Daniel Khashabi and Daniel Levy and Daniel Moseguí González and Danielle Perszyk and Danny Hernandez and Danqi Chen and Daphne Ippolito and Dar Gilboa and David Dohan and David Drakard and David Jurgens and Debajyoti Datta and Deep Ganguli and Denis Emelin and Denis Kleyko and Deniz Yuret and Derek Chen and Derek Tam and Dieuwke Hupkes and Diganta Misra and Dilyar Buzan and Dimitri Coelho Mollo and Diyi Yang and Dong-Ho Lee and Dylan Schrader and Ekaterina Shutova and Ekin Dogus Cubuk and Elad Segal and Eleanor Hagerman and Elizabeth Barnes and Elizabeth Donoway and Ellie Pavlick and Emanuele Rodola and Emma Lam and Eric Chu and Eric Tang and Erkut Erdem and Ernie Chang and Ethan A. Chi and Ethan Dyer and Ethan Jerzak and Ethan Kim and Eunice Engefu Manyasi and Evgenii Zheltonozhskii and Fanyue Xia and Fatemeh Siar and Fernando Martínez-Plumed and Francesca Happé and Francois Chollet and Frieda Rong and Gaurav Mishra and Genta Indra Winata and Gerard de Melo and Germán Kruszewski and Giambattista Parascandolo and Giorgio Mariani and Gloria Wang and Gonzalo Jaimovitch-López and Gregor Betz and Guy Gur-Ari and Hana Galijasevic and Hannah Kim and Hannah Rashkin and Hannaneh Hajishirzi and Harsh Mehta and Hayden Bogar and Henry Shevlin and Hinrich Schütze and Hiromu Yakura and Hongming Zhang and Hugh Mee Wong and Ian Ng and Isaac Noble and Jaap Jumelet and Jack Geissinger and Jackson Kernion and Jacob Hilton and Jaehoon Lee and Jaime Fernández Fisac and James B. Simon and James Koppel and James Zheng and James Zou and Jan Kocoń and Jana Thompson and Janelle Wingfield and Jared Kaplan and Jarema Radom and Jascha Sohl-Dickstein and Jason Phang and Jason Wei and Jason Yosinski and Jekaterina Novikova and Jelle Bosscher and Jennifer Marsh and Jeremy Kim and Jeroen Taal and Jesse Engel and Jesujoba Alabi and Jiacheng Xu and Jiaming Song and Jillian Tang and Joan Waweru and John Burden and John Miller and John U. Balis and Jonathan Batchelder and Jonathan Berant and Jörg Frohberg and Jos Rozen and Jose Hernandez-Orallo and Joseph Boudeman and Joseph Guerr and Joseph Jones and Joshua B. Tenenbaum and Joshua S. Rule and Joyce Chua and Kamil Kanclerz and Karen Livescu and Karl Krauth and Karthik Gopalakrishnan and Katerina Ignatyeva and Katja Markert and Kaustubh D. Dhole and Kevin Gimpel and Kevin Omondi and Kory Mathewson and Kristen Chiafullo and Ksenia Shkaruta and Kumar Shridhar and Kyle McDonell and Kyle Richardson and Laria Reynolds and Leo Gao and Li Zhang and Liam Dugan and Lianhui Qin and Lidia Contreras-Ochando and Louis-Philippe Morency and Luca Moschella and Lucas Lam and Lucy Noble and Ludwig Schmidt and Luheng He and Luis Oliveros Colón and Luke Metz and Lütfi Kerem Şenel and Maarten Bosma and Maarten Sap and Maartje ter Hoeve and Maheen Farooqi and Manaal Faruqui and Mantas Mazeika and Marco Baturan and Marco Marelli and Marco Maru and Maria Jose Ramírez Quintana and Marie Tolkiehn and Mario Giulianelli and Martha Lewis and Martin Potthast and Matthew L. Leavitt and Matthias Hagen and Mátyás Schubert and Medina Orduna Baitemirova and Melody Arnaud and Melvin McElrath and Michael A. Yee and Michael Cohen and Michael Gu and Michael Ivanitskiy and Michael Starritt and Michael Strube and Michał Swędrowski and Michele Bevilacqua and Michihiro Yasunaga and Mihir Kale and Mike Cain and Mimee Xu and Mirac Suzgun and Mitch Walker and Mo Tiwari and Mohit Bansal and Moin Aminnaseri and Mor Geva and Mozhdeh Gheini and Mukund Varma T and Nanyun Peng and Nathan A. Chi and Nayeon Lee and Neta Gur-Ari Krakover and Nicholas Cameron and Nicholas Roberts and Nick Doiron and Nicole Martinez and Nikita Nangia and Niklas Deckers and Niklas Muennighoff and Nitish Shirish Keskar and Niveditha S. Iyer and Noah Constant and Noah Fiedel and Nuan Wen and Oliver Zhang and Omar Agha and Omar Elbaghdadi and Omer Levy and Owain Evans and Pablo Antonio Moreno Casares and Parth Doshi and Pascale Fung and Paul Pu Liang and Paul Vicol and Pegah Alipoormolabashi and Peiyuan Liao and Percy Liang and Peter Chang and Peter Eckersley and Phu Mon Htut and Pinyu Hwang and Piotr Miłkowski and Piyush Patil and Pouya Pezeshkpour and Priti Oli and Qiaozhu Mei and Qing Lyu and Qinlang Chen and Rabin Banjade and Rachel Etta Rudolph and Raefer Gabriel and Rahel Habacker and Ramon Risco and Raphaël Millière and Rhythm Garg and Richard Barnes and Rif A. Saurous and Riku Arakawa and Robbe Raymaekers and Robert Frank and Rohan Sikand and Roman Novak and Roman Sitelew and Ronan LeBras and Rosanne Liu and Rowan Jacobs and Rui Zhang and Ruslan Salakhutdinov and Ryan Chi and Ryan Lee and Ryan Stovall and Ryan Teehan and Rylan Yang and Sahib Singh and Saif M. Mohammad and Sajant Anand and Sam Dillavou and Sam Shleifer and Sam Wiseman and Samuel Gruetter and Samuel R. Bowman and Samuel S. Schoenholz and Sanghyun Han and Sanjeev Kwatra and Sarah A. Rous and Sarik Ghazarian and Sayan Ghosh and Sean Casey and Sebastian Bischoff and Sebastian Gehrmann and Sebastian Schuster and Sepideh Sadeghi and Shadi Hamdan and Sharon Zhou and Shashank Srivastava and Sherry Shi and Shikhar Singh and Shima Asaadi and Shixiang Shane Gu and Shubh Pachchigar and Shubham Toshniwal and Shyam Upadhyay and Shyamolima and Debnath and Siamak Shakeri and Simon Thormeyer and Simone Melzi and Siva Reddy and Sneha Priscilla Makini and Soo-Hwan Lee and Spencer Torene and Sriharsha Hatwar and Stanislas Dehaene and Stefan Divic and Stefano Ermon and Stella Biderman and Stephanie Lin and Stephen Prasad and Steven T. Piantadosi and Stuart M. Shieber and Summer Misherghi and Svetlana Kiritchenko and Swaroop Mishra and Tal Linzen and Tal Schuster and Tao Li and Tao Yu and Tariq Ali and Tatsu Hashimoto and Te-Lin Wu and Théo Desbordes and Theodore Rothschild and Thomas Phan and Tianle Wang and Tiberius Nkinyili and Timo Schick and Timofei Kornev and Titus Tunduny and Tobias Gerstenberg and Trenton Chang and Trishala Neeraj and Tushar Khot and Tyler Shultz and Uri Shaham and Vedant Misra and Vera Demberg and Victoria Nyamai and Vikas Raunak and Vinay Ramasesh and Vinay Uday Prabhu and Vishakh Padmakumar and Vivek Srikumar and William Fedus and William Saunders and William Zhang and Wout Vossen and Xiang Ren and Xiaoyu Tong and Xinran Zhao and Xinyi Wu and Xudong Shen and Yadollah Yaghoobzadeh and Yair Lakretz and Yangqiu Song and Yasaman Bahri and Yejin Choi and Yichi Yang and Yiding Hao and Yifu Chen and Yonatan Belinkov and Yu Hou and Yufang Hou and Yuntao Bai and Zachary Seid and Zhuoye Zhao and Zijian Wang and Zijie J. Wang and Zirui Wang and Ziyi Wu},
  eprint        = {2206.04615},
  primaryclass  = {cs.CL},
  title         = {Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},
  year          = {2023}
}

@misc{sarlin2020superglue,
  archiveprefix = {arXiv},
  author        = {Paul-Edouard Sarlin and Daniel DeTone and Tomasz Malisiewicz and Andrew Rabinovich},
  eprint        = {1911.11763},
  primaryclass  = {cs.CV},
  title         = {SuperGlue: Learning Feature Matching with Graph Neural Networks},
  year          = {2020}
}
@misc{rajpurkar2016squad,
  archiveprefix = {arXiv},
  author        = {Pranav Rajpurkar and Jian Zhang and Konstantin Lopyrev and Percy Liang},
  eprint        = {1606.05250},
  primaryclass  = {cs.CL},
  title         = {SQuAD: 100,000+ Questions for Machine Comprehension of Text},
  year          = {2016}
}
@inproceedings{10.1145/3531146.3533088,
  abstract  = {Responsible innovation on large-scale Language Models (LMs) requires foresight into and in-depth understanding of the risks these models may pose. This paper develops a comprehensive taxonomy of ethical and social risks associated with LMs. We identify twenty-one risks, drawing on expertise and literature from computer science, linguistics, and the social sciences. We situate these risks in our taxonomy of six risk areas: I. Discrimination, Hate speech and Exclusion, II. Information Hazards, III. Misinformation Harms, IV. Malicious Uses, V. Human-Computer Interaction Harms, and VI. Environmental and Socioeconomic harms. For risks that have already been observed in LMs, the causal mechanism leading to harm, evidence of the risk, and approaches to risk mitigation are discussed. We further describe and analyse risks that have not yet been observed but are anticipated based on assessments of other language technologies, and situate these in the same taxonomy. We underscore that it is the responsibility of organizations to engage with the mitigations we discuss throughout the paper. We close by highlighting challenges and directions for further research on risk evaluation and mitigation with the goal of ensuring that language models are developed responsibly.},
  address   = {New York, NY, USA},
  author    = {Weidinger, Laura and Uesato, Jonathan and Rauh, Maribeth and Griffin, Conor and Huang, Po-Sen and Mellor, John and Glaese, Amelia and Cheng, Myra and Balle, Borja and Kasirzadeh, Atoosa and Biles, Courtney and Brown, Sasha and Kenton, Zac and Hawkins, Will and Stepleton, Tom and Birhane, Abeba and Hendricks, Lisa Anne and Rimell, Laura and Isaac, William and Haas, Julia and Legassick, Sean and Irving, Geoffrey and Gabriel, Iason},
  booktitle = {Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  doi       = {10.1145/3531146.3533088},
  isbn      = {9781450393522},
  keywords  = {language models, risk assessment, responsible AI, technology risks, responsible innovation},
  location  = {Seoul, Republic of Korea},
  numpages  = {16},
  pages     = {214–229},
  publisher = {Association for Computing Machinery},
  series    = {FAccT '22},
  title     = {Taxonomy of Risks Posed by Language Models},
  url       = {https://doi.org/10.1145/3531146.3533088},
  year      = {2022}
}

@misc{anil2023palm,
  archiveprefix = {arXiv},
  author        = {Rohan Anil and Andrew M. Dai and Orhan Firat and Melvin Johnson and Dmitry Lepikhin and Alexandre Passos and Siamak Shakeri and Emanuel Taropa and Paige Bailey and Zhifeng Chen and Eric Chu and Jonathan H. Clark and Laurent El Shafey and Yanping Huang and Kathy Meier-Hellstern and Gaurav Mishra and Erica Moreira and Mark Omernick and Kevin Robinson and Sebastian Ruder and Yi Tay and Kefan Xiao and Yuanzhong Xu and Yujing Zhang and Gustavo Hernandez Abrego and Junwhan Ahn and Jacob Austin and Paul Barham and Jan Botha and James Bradbury and Siddhartha Brahma and Kevin Brooks and Michele Catasta and Yong Cheng and Colin Cherry and Christopher A. Choquette-Choo and Aakanksha Chowdhery and Clément Crepy and Shachi Dave and Mostafa Dehghani and Sunipa Dev and Jacob Devlin and Mark Díaz and Nan Du and Ethan Dyer and Vlad Feinberg and Fangxiaoyu Feng and Vlad Fienber and Markus Freitag and Xavier Garcia and Sebastian Gehrmann and Lucas Gonzalez and Guy Gur-Ari and Steven Hand and Hadi Hashemi and Le Hou and Joshua Howland and Andrea Hu and Jeffrey Hui and Jeremy Hurwitz and Michael Isard and Abe Ittycheriah and Matthew Jagielski and Wenhao Jia and Kathleen Kenealy and Maxim Krikun and Sneha Kudugunta and Chang Lan and Katherine Lee and Benjamin Lee and Eric Li and Music Li and Wei Li and YaGuang Li and Jian Li and Hyeontaek Lim and Hanzhao Lin and Zhongtao Liu and Frederick Liu and Marcello Maggioni and Aroma Mahendru and Joshua Maynez and Vedant Misra and Maysam Moussalem and Zachary Nado and John Nham and Eric Ni and Andrew Nystrom and Alicia Parrish and Marie Pellat and Martin Polacek and Alex Polozov and Reiner Pope and Siyuan Qiao and Emily Reif and Bryan Richter and Parker Riley and Alex Castro Ros and Aurko Roy and Brennan Saeta and Rajkumar Samuel and Renee Shelby and Ambrose Slone and Daniel Smilkov and David R. So and Daniel Sohn and Simon Tokumine and Dasha Valter and Vijay Vasudevan and Kiran Vodrahalli and Xuezhi Wang and Pidong Wang and Zirui Wang and Tao Wang and John Wieting and Yuhuai Wu and Kelvin Xu and Yunhan Xu and Linting Xue and Pengcheng Yin and Jiahui Yu and Qiao Zhang and Steven Zheng and Ce Zheng and Weikang Zhou and Denny Zhou and Slav Petrov and Yonghui Wu},
  eprint        = {2305.10403},
  primaryclass  = {cs.CL},
  title         = {PaLM 2 Technical Report},
  year          = {2023}
}

@online{ChatGPT-announcement,
  author = {OpenAI},
  date   = {2022-11-30},
  title  = {Introducing ChatGPT},
  url    = {https://openai.com/blog/chatgpt},
  year   = {2022}
}

@article{devlin2018bert,
  author  = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal = {arXiv preprint arXiv:1810.04805},
  title   = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  year    = {2018}
}

@online{google_trends_ki,
  author = {Google},
  note   = {Accessed: \today},
  title  = {Google Trends},
  url    = {https://trends.google.com/trends/explore?date=2021-01-11%202023-12-07&q=%2Fm%2F0mkz&hl=de-DE}
}

@online{google:llm,
  author  = {Google},
  date    = {2023-08-08},
  title   = {Einführung in große Sprachmodelle},
  url     = {https://developers.google.com/machine-learning/resources/intro-llms?hl=de},
  urldate = {2023-12-10},
  year    = {2023}
}

@book{kounev2020systems,
  title={Systems Benchmarking: For Scientists and Engineers},
  author={Kounev, S. and Lange, K.D. and von Kistowski, J.},
  isbn={9783030417048},
  url={https://books.google.de/books?id=29JBzQEACAAJ},
  year={2020},
  publisher={Springer International Publishing}
}


@article{llm_comparison,
  author = {Guo, Tong},
  doi    = {10.36227/techrxiv.14820348.v1},
  month  = {06},
  pages  = {},
  title  = {A Comprehensive Comparison of Pre-training Language Models},
  year   = {2021}
}



@misc{lv2023parameter,
  archiveprefix = {arXiv},
  author        = {Kai Lv and Yuqing Yang and Tengxiao Liu and Qinghui Gao and Qipeng Guo and Xipeng Qiu},
  eprint        = {2306.09782},
  primaryclass  = {cs.CL},
  title         = {Full Parameter Fine-tuning for Large Language Models with Limited Resources},
  year          = {2023}
}

@misc{naveed2023comprehensive,
  archiveprefix = {arXiv},
  author        = {Humza Naveed and Asad Ullah Khan and Shi Qiu and Muhammad Saqib and Saeed Anwar and Muhammad Usman and Naveed Akhtar and Nick Barnes and Ajmal Mian},
  eprint        = {2307.06435},
  primaryclass  = {cs.CL},
  title         = {A Comprehensive Overview of Large Language Models},
  year          = {2023}
}


@book{NLP_2008,
  author = {Jurafsky, Daniel and Martin, James},
  month  = {02},
  pages  = {},
  title  = {Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition},
  volume = {2},
  year   = {2008}
}



@article{Peng_2023,
  author    = {Peng, Cheng and Yang, Xi and Chen, Aokun and Smith, Kaleb E. and PourNejatian, Nima and Costa, Anthony B. and Martin, Cheryl and Flores, Mona G. and Zhang, Ying and Magoc, Tanja and Lipori, Gloria and Mitchell, Duane A. and Ospina, Naykky S. and Ahmed, Mustafa M. and Hogan, William R. and Shenkman, Elizabeth A. and Guo, Yi and Bian, Jiang and Wu, Yonghui},
  doi       = {10.1038/s41746-023-00958-w},
  issn      = {2398-6352},
  journal   = {npj Digital Medicine},
  month     = nov,
  number    = {1},
  publisher = {Springer Science and Business Media LLC},
  title     = {A study of generative large language model for medical research and healthcare},
  url       = {http://dx.doi.org/10.1038/s41746-023-00958-w},
  volume    = {6},
  year      = {2023}
}

@misc{tamkin2021understanding,
  archiveprefix = {arXiv},
  author        = {Alex Tamkin and Miles Brundage and Jack Clark and Deep Ganguli},
  eprint        = {2102.02503},
  primaryclass  = {cs.CL},
  title         = {Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models},
  year          = {2021}
}

@inbook{Taulli2023,
  abstract  = {In December 2015, a group of tech veterans -- including Elon Musk, Reid Hoffman, Peter Thiel, and Sam Altman -- founded OpenAI. They pledged over {\$}1 billion for the venture.},
  address   = {Berkeley, CA},
  author    = {Taulli, Tom},
  booktitle = {Generative AI: How ChatGPT and Other AI Tools Will Revolutionize Business},
  doi       = {10.1007/978-1-4842-9367-6_5},
  isbn      = {978-1-4842-9367-6},
  pages     = {93--125},
  publisher = {Apress},
  title     = {Large Language Models},
  url       = {https://doi.org/10.1007/978-1-4842-9367-6_5},
  year      = {2023}
}


@article{Tokayev_2023,
  abstractnote = {&amp;lt;p&amp;gt;Large Language Models (LLMs) have become increasingly prevalent in various sectors including healthcare, finance, and customer service, among others. While these models offer impressive capabilities ranging from natural language understanding to text generation, their widespread adoption has raised a series of ethical concerns. This research aims to provide an in-depth analysis of these ethical implications, organized into several categories for better understanding. On the societal front, LLMs can amplify existing biases found in their training data, contributing to unfair or harmful outputs. Additionally, these models can be employed to generate fake news or misleading information, undermining public trust and contributing to social discord. There is also the risk of cultural homogenization as these technologies may promote dominant cultures at the expense of local or minority perspectives. From an economic and environmental standpoint, the energy-intensive process of training LLMs results in a significant carbon footprint, raising sustainability concerns. The advent of LLMs also presents economic challenges, particularly the potential displacement of jobs due to automation, exacerbating employment insecurity. On the operational level, LLMs pose technical challenges such as a lack of transparency, often referred to as the &amp;quot;black box&amp;quot; nature of these models, making it difficult to understand or rectify their behavior. This opacity can lead to an over-reliance on LLMs for critical decision-making, without adequate scrutiny or understanding of their limitations. Further, there are significant privacy concerns, as these models may inadvertently generate outputs containing sensitive or confidential information gleaned from their training data. The human experience is also affected, as reliance on LLMs for various tasks can lead to depersonalization of human interactions. Finally, questions surrounding access, equity, and governance of these technologies come to the forefront. Control and accountability remain nebulous, especially when LLMs are used for critical decision-making or actions that have direct human impact. Moreover, the access to such advanced technologies may be limited to well-resourced entities, widening existing inequalities. This research seeks to delve into these issues, aiming to spark informed discussions and guide future policy.&amp;lt;/p&amp;gt;},
  author       = {Tokayev, Kassym-Jomart},
  journal      = {International Journal of Social Analytics},
  month        = {9},
  number       = {9},
  pages        = {17–33},
  title        = {Ethical Implications of Large Language Models A Multidimensional Exploration of Societal, Economic, and Technical Concerns},
  url          = {https://norislab.com/index.php/ijsa/article/view/42},
  volume       = {8},
  year         = {2023}
}

@misc{touvron2023llama,
  archiveprefix = {arXiv},
  author        = {Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
  eprint        = {2302.13971},
  primaryclass  = {cs.CL},
  title         = {LLaMA: Open and Efficient Foundation Language Models},
  year          = {2023}
}

@misc{vaswani2023attention,
  archiveprefix = {arXiv},
  author        = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  eprint        = {1706.03762},
  primaryclass  = {cs.CL},
  title         = {Attention Is All You Need},
  year          = {2023}
}

@misc{yang2023harnessing,
  archiveprefix = {arXiv},
  author        = {Jingfeng Yang and Hongye Jin and Ruixiang Tang and Xiaotian Han and Qizhang Feng and Haoming Jiang and Bing Yin and Xia Hu},
  eprint        = {2304.13712},
  primaryclass  = {cs.CL},
  title         = {Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond},
  year          = {2023}
}

@misc{yetiştiren2023evaluating,
  archiveprefix = {arXiv},
  author        = {Burak Yetiştiren and Işık Özsoy and Miray Ayerdem and Eray Tüzün},
  eprint        = {2304.10778},
  primaryclass  = {cs.SE},
  title         = {Evaluating the Code Quality of AI-Assisted Code Generation Tools: An Empirical Study on GitHub Copilot, Amazon CodeWhisperer, and ChatGPT},
  year          = {2023}
}

@inproceedings{zellers2019hellaswag,
  author    = {Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  title     = {HellaSwag: Can a Machine Really Finish Your Sentence?},
  year      = {2019}
}

@misc{zhou2023comprehensive,
  archiveprefix = {arXiv},
  author        = {Ce Zhou and Qian Li and Chen Li and Jun Yu and Yixin Liu and Guangjing Wang and Kai Zhang and Cheng Ji and Qiben Yan and Lifang He and Hao Peng and Jianxin Li and Jia Wu and Ziwei Liu and Pengtao Xie and Caiming Xiong and Jian Pei and Philip S. Yu and Lichao Sun},
  eprint        = {2302.09419},
  primaryclass  = {cs.AI},
  title         = {A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT},
  year          = {2023}
}

@misc{chang2023survey,
  archiveprefix = {arXiv},
  author        = {Yupeng Chang and Xu Wang and Jindong Wang and Yuan Wu and Linyi Yang and Kaijie Zhu and Hao Chen and Xiaoyuan Yi and Cunxiang Wang and Yidong Wang and Wei Ye and Yue Zhang and Yi Chang and Philip S. Yu and Qiang Yang and Xing Xie},
  eprint        = {2307.03109},
  primaryclass  = {cs.CL},
  title         = {A Survey on Evaluation of Large Language Models},
  year          = {2023}
}

@misc{liang2023holistic,
  archiveprefix = {arXiv},
  author        = {Percy Liang and Rishi Bommasani and Tony Lee and Dimitris Tsipras and Dilara Soylu and Michihiro Yasunaga and Yian Zhang and Deepak Narayanan and Yuhuai Wu and Ananya Kumar and Benjamin Newman and Binhang Yuan and Bobby Yan and Ce Zhang and Christian Cosgrove and Christopher D. Manning and Christopher Ré and Diana Acosta-Navas and Drew A. Hudson and Eric Zelikman and Esin Durmus and Faisal Ladhak and Frieda Rong and Hongyu Ren and Huaxiu Yao and Jue Wang and Keshav Santhanam and Laurel Orr and Lucia Zheng and Mert Yuksekgonul and Mirac Suzgun and Nathan Kim and Neel Guha and Niladri Chatterji and Omar Khattab and Peter Henderson and Qian Huang and Ryan Chi and Sang Michael Xie and Shibani Santurkar and Surya Ganguli and Tatsunori Hashimoto and Thomas Icard and Tianyi Zhang and Vishrav Chaudhary and William Wang and Xuechen Li and Yifan Mai and Yuhui Zhang and Yuta Koreeda},
  eprint        = {2211.09110},
  primaryclass  = {cs.CL},
  title         = {Holistic Evaluation of Language Models},
  year          = {2023}
}

@inproceedings{derczynski-2016-complementarity,
  abstract  = {This paper addresses the problem of quantifying the differences between entity extraction systems, where in general only a small proportion a document should be selected. Comparing overall accuracy is not very useful in these cases, as small differences in accuracy may correspond to huge differences in selections over the target minority class. Conventionally, one may use per-token complementarity to describe these differences, but it is not very useful when the set is heavily skewed. In such situations, which are common in information retrieval and entity recognition, metrics like precision and recall are typically used to describe performance. However, precision and recall fail to describe the differences between sets of objects selected by different decision strategies, instead just describing the proportional amount of correct and incorrect objects selected. This paper presents a method for measuring complementarity for precision, recall and F-score, quantifying the difference between entity extraction approaches.},
  address   = {Portoro{\v{z}}, Slovenia},
  author    = {Derczynski, Leon},
  booktitle = {Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)},
  editor    = {Calzolari, Nicoletta  and
               Choukri, Khalid  and
               Declerck, Thierry  and
               Goggi, Sara  and
               Grobelnik, Marko  and
               Maegaard, Bente  and
               Mariani, Joseph  and
               Mazo, Helene  and
               Moreno, Asuncion  and
               Odijk, Jan  and
               Piperidis, Stelios},
  month     = may,
  pages     = {261--266},
  publisher = {European Language Resources Association (ELRA)},
  title     = {Complementarity, {F}-score, and {NLP} Evaluation},
  url       = {https://aclanthology.org/L16-1040},
  year      = {2016}
}

@misc{chiang2023large,
  archiveprefix = {arXiv},
  author        = {Cheng-Han Chiang and Hung-yi Lee},
  eprint        = {2305.01937},
  primaryclass  = {cs.CL},
  title         = {Can Large Language Models Be an Alternative to Human Evaluations?},
  year          = {2023}
}


@misc{zhang2020bertscore,
  archiveprefix = {arXiv},
  author        = {Tianyi Zhang and Varsha Kishore and Felix Wu and Kilian Q. Weinberger and Yoav Artzi},
  eprint        = {1904.09675},
  primaryclass  = {cs.CL},
  title         = {BERTScore: Evaluating Text Generation with BERT},
  year          = {2020}
}